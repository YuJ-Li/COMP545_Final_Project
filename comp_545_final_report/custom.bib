% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

% Context-is-Key benchmark and LLM forecasting

@article{williams2024context,
  title={Context is Key: A Benchmark for Forecasting with Essential Textual Information},
  author={Williams, Andrew Robert and Rasul, Kashif and Khorasani, Arian and Adamopoulos, George and Bhagwatkar, Rishika and Biloš, Marin and Ghonia, Hena and Hassen, Nadhir Vincent and Schneider, Anderson and Garg, Sahil and others},
  journal={arXiv preprint arXiv:2410.18959},
  year={2024}
}

@article{gruver2023llm,
  title={Large language models are zero-shot time series forecasters},
  author={Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% Data sources (7 domains from CiK)

@article{sengupta2018nsrdb,
  title={The national solar radiation data base (NSRDB)},
  author={Sengupta, Manajit and Xie, Yu and Lopez, Anthony and Habte, Aron and Maclaurin, Galen and Shelby, James},
  journal={Renewable and sustainable energy reviews},
  volume={89},
  pages={51--60},
  year={2018}
}

@article{godahewa2021monash,
  title={Monash time series forecasting archive},
  author={Godahewa, Rakshitha and Bergmeir, Christoph and Webb, Geoffrey I and Hyndman, Rob J and Montero-Manso, Pablo},
  journal={arXiv preprint arXiv:2105.06643},
  year={2021}
}

@article{chen2001pems,
  title={Freeway performance measurement system: mining loop detector data},
  author={Chen, Chao and Petty, Karl and Skabardonis, Alexander and Varaiya, Pravin and Jia, Zhanfeng},
  journal={Transportation research record},
  volume={1748},
  number={1},
  pages={96--102},
  year={2001}
}

@misc{usbls2024,
  title={Unemployment rate [various locations]},
  author={{U.S. Bureau of Labor Statistics}},
  year={2024},
  url={https://fred.stlouisfed.org/},
  note={Accessed on 2024-08-30, retrieved from FRED}
}

@misc{villemtl2020,
  title={Interventions des pompiers de Montr{\'e}al},
  author={{Ville de Montr{\'e}al}},
  year={2020},
  url={https://www.donneesquebec.ca/recherche/dataset/vmtl-interventions-service-securite-incendie-montreal},
  note={Updated on 2024-09-12, accessed on 2024-09-13}
}

@article{gamella2024causal,
  title={The causal chambers: Real physical systems as a testbed for AI methodology},
  author={Gamella, Juan L and B{\"u}hlmann, Peter and Peters, Jonas},
  journal={arXiv preprint arXiv:2404.11341},
  year={2024}
}

% LLM models

@article{dubey2024llama,
  title={The Llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@misc{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Hanna, Emma Bou and Bressand, Florian and others},
  year={2024},
  url={https://arxiv.org/abs/2401.04088}
}

@article{achiam2023gpt4,
  title={GPT-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

% Time series foundation models

@article{ansari2024chronos,
  title={Chronos: Learning the language of time series},
  author={Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Sundar and Arango, Sebastian Pineda and Kapoor, Shubham and others},
  journal={arXiv preprint arXiv:2403.07815},
  year={2024}
}

@article{rasul2023lagllama,
  title={Lag-Llama: Towards foundation models for time series forecasting},
  author={Rasul, Kashif and Ashok, Arjun and Williams, Andrew Robert and Khorasani, Arian and Adamopoulos, George and Bhagwatkar, Rishika and Biloš, Marin and Ghonia, Hena and Hassen, Nadhir Vincent and Schneider, Anderson and others},
  journal={arXiv preprint arXiv:2310.08278},
  year={2023}
}

@article{jin2024timellm,
  title={Time-LLM: Time series forecasting by reprogramming large language models},
  author={Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and Wen, Qingsong},
  journal={arXiv preprint arXiv:2310.03589},
  year={2024}
}

% Surveys and general TS forecasting

@article{liang2024foundation,
  title={Foundation models for time series analysis: A tutorial and survey},
  author={Liang, Yuxuan and Wen, Haomin and Nie, Yuqi and Jiang, Yushan and Jin, Ming and Song, Dongjin and Pan, Shirui and Wen, Qingsong},
  journal={arXiv preprint arXiv:2403.14735},
  year={2024}
}

@article{chen2023long,
  title={Long sequence time-series forecasting with deep learning: A survey},
  author={Chen, Zonglei and Ma, Minbo and Li, Tianrui and Wang, Hongjun and Li, Chongshou},
  journal={Information Fusion},
  volume={97},
  pages={101819},
  year={2023}
}

@article{lim2021time,
  title={Time-series forecasting with deep learning: a survey},
  author={Lim, Bryan and Zohren, Stefan},
  journal={Philosophical Transactions of the Royal Society A},
  volume={379},
  number={2194},
  pages={20200209},
  year={2021}
}

@article{jin2024survey,
  title={A survey on time series foundation models},
  author={Jin, Ming and others},
  journal={arXiv preprint},
  year={2024},
  note={Placeholder - replace with actual citation if available}
}

% Classical forecasting methods

@book{hyndman2018forecasting,
  title={Forecasting: principles and practice},
  author={Hyndman, Rob J and Athanasopoulos, George},
  year={2018},
  publisher={OTexts}
}

@book{box2015time,
  title={Time series analysis: forecasting and control},
  author={Box, George EP and Jenkins, Gwilym M and Reinsel, Gregory C and Ljung, Greta M},
  year={2015},
  edition={fifth},
  publisher={John Wiley \& Sons}
}

@article{gardner1985exponential,
  title={Exponential smoothing: The state of the art},
  author={Gardner Jr, Everette S},
  journal={Journal of Forecasting},
  volume={4},
  number={1},
  pages={1--28},
  year={1985}
}

@book{hyndman2008forecasting,
  title={Forecasting with exponential smoothing: the state space approach},
  author={Hyndman, Rob and Koehler, Anne B and Ord, J Keith and Snyder, Ralph D},
  year={2008},
  publisher={Springer Science \& Business Media}
}

% Machine learning tools

@inproceedings{chen2016xgboost,
  title={XGBoost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={785--794},
  year={2016}
}

@misc{statsmodels,
  title={statsmodels: Econometric and statistical modeling with python},
  author={Seabold, Skipper and Perktold, Josef},
  year={2010},
  howpublished={\url{https://www.statsmodels.org/}}
}

% Memorization and trust

@article{macdonald2025trust,
  title={The Memorization Problem: Can We Trust LLMs' Economic Forecasts?},
  author={MacDonald, Kyle and others},
  journal={Federal Reserve Working Paper},
  year={2025},
  note={Placeholder - update with arXiv number when available}
}

% Specialised deep learning models

@article{nie2022patchtst,
  title={A time series is worth 64 words: Long-term forecasting with transformers},
  author={Nie, Yuqi and Nguyen, Nam H and Sinthong, Phanwadee and Kalagnanam, Jayant},
  journal={arXiv preprint arXiv:2211.14730},
  year={2022}
}

% Additional References 

@article{gneiting2007strictly,
  title={Strictly proper scoring rules, prediction, and estimation},
  author={Gneiting, Tilmann and Raftery, Adrian E},
  journal={Journal of the American statistical Association},
  volume={102},
  number={477},
  pages={359--378},
  year={2007}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}